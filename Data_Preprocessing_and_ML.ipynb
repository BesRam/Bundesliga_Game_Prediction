{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3913e05-5dba-4f06-81b1-23c0f4246090",
   "metadata": {},
   "source": [
    "# Data Preprocessing, Explorative Data Analysis (EDA) and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19644b5a-a467-49af-a8b6-af9640886adb",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we will embark on a comprehensive journey through data handling, analysis, and modeling using a dataset comprising football match and weather data retrieved from a MySQL database. Initially, we will merge and organize the datasets to create a unified view of the data. Following this, we will conduct thorough data cleansing to ensure data quality and perform exploratory data analysis (EDA) to uncover insights and patterns. The next stages involve feature engineering to prepare the data for machine learning. We will then develop and train a predictive model, evaluate its performance, and fine-tune it through hyperparameter adjustments. Finally, we will utilize our model to predict outcomes of future football matches, providing actionable insights and demonstrating the practical application of our analytical endeavors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecaf20d-c1f1-4884-a347-e86ebce69906",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d2e31-1688-46ac-9fa1-dc96293e74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import openmeteo_requests # Custom module for managing requests to the OpenMeteo API.\n",
    "import requests_cache # Caches the responses of HTTP requests to enhance efficiency and reduce load times.\n",
    "from retry_requests import retry # Provides a mechanism to automatically retry HTTP requests on failure.\n",
    "import time # Allows us to use functionality related to time, such as delays and timestamp calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081dc29-6f50-4928-9a53-151fc46e4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, classification_report, auc\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae332e59-9eb4-40e9-8d5c-da349c672d27",
   "metadata": {},
   "source": [
    "## 2. Get Football Matches Data from MySQL and Store in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240596f-7863-4c36-a426-27d623f15f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Establish a connection to the MySQL database using provided credentials.\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        database='adsfootball',\n",
    "        user='root',\n",
    "        password='abcabc123'\n",
    "    )\n",
    "\n",
    "    # Check if the database connection was successfully established\n",
    "    if connection.is_connected():\n",
    "        # SQL query to fetch all records from the 'matches' table\n",
    "        query = \"SELECT * FROM matches\"\n",
    "        # Execute the SQL query and store the result in a DataFrame for easy data manipulation\n",
    "        all_matches_df = pd.read_sql_query(query, connection)\n",
    "        \n",
    "except Error as e:\n",
    "    # Print any errors encountered during the database operation\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the database connection is closed to free system resources\n",
    "    if connection.is_connected():\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40952f4e-d430-45c4-8a16-43805e937a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e13f51-9b5a-4ced-9c84-41937b77eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe713ad6-51fd-4f47-a6b2-b0a47fe1951f",
   "metadata": {},
   "source": [
    "## 3. Get Weather Data from MySQL and Store in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7252475-286b-4e5d-975a-60274c8a4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Establish a connection to the MySQL database using the provided credentials.\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        database='adsfootball',\n",
    "        user='root',\n",
    "        password='abcabc123'\n",
    "    )\n",
    "\n",
    "    # Check if the database connection was successfully established\n",
    "    if connection.is_connected():\n",
    "        # Define an SQL query to retrieve all records from the 'weather' table\n",
    "        query = \"SELECT * FROM weather\"\n",
    "        # Execute the SQL query and store the result in a DataFrame for further analysis\n",
    "        weather_df = pd.read_sql(query, connection)\n",
    "        \n",
    "except Error as e:\n",
    "    # Handle any errors that occur during the database operation and print the error message\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the database connection is closed to free system resources\n",
    "    if connection.is_connected():\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ab56b-a2aa-4969-a6fe-bae2b002151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6343ef-bc0e-4c92-9963-6c4fde49a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae52c6-f396-42b5-b830-107907429efd",
   "metadata": {},
   "source": [
    "## 4. Data Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77da2d-6b88-456c-833e-da18fa028597",
   "metadata": {},
   "source": [
    "After successfully loading our datasets, the next step involves merging the weather data with the football match data. This crucial integration combines key information from both datasets, facilitating a detailed analysis of how weather conditions may influence match outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0e596-4fe5-4e94-acec-2b6f3426336b",
   "metadata": {},
   "source": [
    "### 4.1 Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766c785-6a2e-4ca9-ac2b-e1d9d27ebda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset = all_matches_df.merge(weather_df[['id', 'weather_code', 'mean_temperature', 'precipitation_sum', 'rain_sum', 'snowfall_sum']], on='id', how='left')\n",
    "full_matches_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de187652-f0b5-4730-882a-9e22fd0a2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6677b-e5d8-4e04-a537-35e3097ef9a5",
   "metadata": {},
   "source": [
    "### 4.2 Categorize Weather Conditions Using WMO Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79415d9a-99aa-44ce-bba9-6310f3f70ece",
   "metadata": {},
   "source": [
    "After successfully merging both datasets, our next task is to categorize the weather codes into comprehensive values as outlined below:\n",
    "\n",
    "- **Sunny or Clear**: Codes 0-19 (conditions without precipitation and significant cloud cover)\n",
    "- **Cloudy**: Codes 20-29 and 40-49 (conditions with previous precipitation, fog, or thunderstorms that have ceased and specifically for fog or ice fog at observation)\n",
    "- **Rainy**: Codes 50-69, 80-82, 91-92, 95-97, 99 (various forms of drizzle, rain, rain showers and thunderstorms with rain) \n",
    "- **Snowy**: Codes 70-79, 83-86, 93-94 (various forms of snowfall, snow showers and thunderstorms with snow)\n",
    "\n",
    "For a complete reference of these codes, please visit [WMO Codes Table](https://www.nodc.noaa.gov/archive/arc0021/0002199/1.1/data/0-data/HTML/WMO-CODE/WMO4677.HTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d78751-1f91-4f59-9eb0-ff669ab37512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize weather codes\n",
    "def categorize_weather(code):\n",
    "    if code in range(0, 20):\n",
    "        return 'Clear'\n",
    "    elif code in range(20, 30) or code in range(40, 50):\n",
    "        return 'Cloudy'\n",
    "    elif code in range(50, 70) or code in range(80, 83) or code in range(91, 93) or code in range(95, 98) or code == 99:\n",
    "        return 'Rainy'\n",
    "    elif code in range(70, 80) or code in range(83, 87) or code in range(93, 95):\n",
    "        return 'Snowy'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the function to the weather_code column\n",
    "full_matches_dataset['weather_category'] = full_matches_dataset['weather_code'].apply(categorize_weather)\n",
    "full_matches_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af30455-3509-480e-87b7-ce24173fb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad89c46-938c-4b95-9e63-4a3a5f0ece4e",
   "metadata": {},
   "source": [
    "### 4.3 Categorize Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd6d71-de36-43c6-a4f5-3af5283140c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' to datetime to just extract the hour\n",
    "full_matches_dataset['time'] = pd.to_datetime(full_matches_dataset['time'], format='%H:%M').dt.hour\n",
    "\n",
    "# Define a function to categorize times into different parts of the day\n",
    "def categorize_time(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "# Apply the function to the 'time' column\n",
    "full_matches_dataset['time_of_day'] = full_matches_dataset['time'].apply(categorize_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e9b25-6067-41a1-91b5-5e25c8c62219",
   "metadata": {},
   "source": [
    "### 4.4 Organize the Columns Order and Change Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9831bb-9f23-4515-a414-95d245393ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_ordered = [\n",
    "    'id', 'date', 'time', 'time_of_day', 'season', 'comp', 'round', 'day',\n",
    "    'team', 'opponent', 'venue', 'captain', 'formation',\n",
    "    'result', 'gf', 'ga', 'xg', 'xga', 'sh', 'sot', 'poss', 'fk', 'pk',\n",
    "    'dist', 'weather_category', 'mean_temperature', 'precipitation_sum', 'rain_sum', 'snowfall_sum',\n",
    "    'stadium', 'city', 'latitude', 'longitude', 'weather_code',\n",
    "    'attendance', 'referee', 'notes'\n",
    "]\n",
    "\n",
    "# Change order of the dataframe\n",
    "full_matches_dataset = full_matches_dataset[columns_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ebf13-d85c-4e99-97bb-21dbe63120c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0abf5d-7c11-4795-900a-823102f3c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names to more meaningful names\n",
    "full_matches_dataset.columns = [\n",
    "    'id', 'date', 'time', 'time_of_day', 'season', 'competition', 'round', 'match_day',\n",
    "    'team', 'opponent', 'venue', 'captain', 'formation',\n",
    "    'result', 'goals_for', 'goals_against', 'expected_goals', 'expected_goals_against', 'shots', 'shots_on_target', 'possession', 'free_kicks', 'penalties',\n",
    "    'distance_covered', 'weather_category', 'mean_temperature', 'precipitation_sum', 'rain_sum', 'snowfall_sum',\n",
    "    'stadium', 'city', 'latitude', 'longitude', 'weather_code',\n",
    "    'attendance', 'referee', 'notes'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3711f5-1407-4b1b-afcb-68233cb6cea7",
   "metadata": {},
   "source": [
    "### 4.5 Column Descriptions for the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e36a9-cf5a-4a77-9ba6-b2b3b98405f1",
   "metadata": {},
   "source": [
    "1. **date**: The date on which the match was played.\n",
    "2. **time**: The kickoff time of the match.\n",
    "3. **time_of_day**: Category of the time of the match.\n",
    "4. **season**: The football season year during which the match was played.\n",
    "5. **competition**: The name of the league or competition (e.g., Bundesliga).\n",
    "6. **round**: Indicates the matchweek number within the season.\n",
    "7. **match_day**: Weekday of the game.\n",
    "8. **team**: The name of the team from whose perspective the match data is recorded.\n",
    "9. **opponent**: The name of the opposing team.\n",
    "10. **venue**: Whether the team was playing at home or away.\n",
    "11. **captain**: The captain of the team for that match.\n",
    "12. **formation**: The playing formation of the team.\n",
    "13. **result**: The match result from the team's perspective (Win, Draw, Loss).\n",
    "14. **goals_for**: Goals scored by the team.\n",
    "15. **goals_against**: Goals conceded by the team.\n",
    "16. **expected_goals**: Expected goals based on match play and opportunities.\n",
    "17. **expected_goals_against**: Expected goals against based on the opposition's play and opportunities.\n",
    "18. **shots**: Total number of shots taken by the team.\n",
    "19. **shots_on_target**: Shots on target by the team.\n",
    "20. **possession**: Percentage of match time the team controlled the ball.\n",
    "21. **free_kicks**: Number of free kicks taken by the team.\n",
    "22. **penalties**: Number of penalties taken by the team.\n",
    "23. **distance_covered**: Total distance covered by the team during the match.\n",
    "24. **weather_category**: General weather conditions during the match (e.g., Clear, Rainy).\n",
    "25. **mean_temperature**: Average temperature during the match.\n",
    "26. **precipitation_sum**: Total precipitation during the match in millimeters.\n",
    "27. **rain_sum**: Total rainfall during the match in millimeters.\n",
    "28. **snowfall_sum**: Total snowfall during the match in centimeters.\n",
    "29. **stadium**: Stadium where the match was held.\n",
    "30. **city**: City in which the match was played.\n",
    "31. **latitude**: Geographic latitude of the match location.\n",
    "32. **longitude**: Geographic longitude of the match location.\n",
    "33. **weather_code**: Weather conditions coded according to WMO standards.\n",
    "34. **attendance**: Number of spectators present at the match.\n",
    "35. **referee**: Referee officiating the match.\n",
    "36. **notes**: Some notes from the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b283ee-323b-4ad4-8dd6-7e46751fd1ff",
   "metadata": {},
   "source": [
    "## 5. Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df3ee2-f217-4345-9a1d-3cb8d64951b0",
   "metadata": {},
   "source": [
    "In this chapter, we focus on the crucial process of data cleansing to ensure the integrity and accuracy of our combined dataset. By identifying and correcting inconsistencies, handling missing values, and removing any anomalies or outliers, we prepare our data for robust and reliable analytical and predictive modeling tasks. This stage is essential for optimizing the dataset's quality, leading to more accurate and meaningful insights and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39e5f8-dfab-4ca4-a6b0-a05e4035f609",
   "metadata": {},
   "source": [
    "### 5.1 Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b66c6d-63c6-4cdd-8fda-cd76b463d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many null values the columns have\n",
    "full_matches_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df70612f-1e7c-4a22-aa42-5fd28e4c26c4",
   "metadata": {},
   "source": [
    "Now we see that there are some columns which have some null values. We decide to take following actions:\n",
    "- **expected_goals:** As the amount of missing values is small, we want to take the mean of the column as value.\n",
    "- **expected_goals_against:** Same as expected_goals.\n",
    "- **free_kicks:** Here we want to take the median as value for the missing values.\n",
    "- **distance_covered:** Same as expected_goals and expected_goals_against.\n",
    "- **attendance:** This is the column with the second most missing values. Because of that, we fill all missing values with 0 and create another column called 'no_audience' which contains a boolean to check if the game had an audience.\n",
    "- **notes:** This column contains mainly missing values. In this case, we delete this column from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c7991-9735-48f5-966b-9ee598f7b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset['expected_goals'] = full_matches_dataset['expected_goals'].fillna(full_matches_dataset['expected_goals'].mean())\n",
    "full_matches_dataset['expected_goals_against'] = full_matches_dataset['expected_goals_against'].fillna(full_matches_dataset['expected_goals_against'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e234794-e3ef-4e8e-81b0-65e31b55667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset['free_kicks'] = full_matches_dataset['free_kicks'].fillna(full_matches_dataset['free_kicks'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6e1a2-5a5f-47cd-9d91-137b68fd009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset['distance_covered'] = full_matches_dataset['distance_covered'].fillna(full_matches_dataset['distance_covered'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486e234-5673-4366-aa61-99778d339b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset['attendance'] = full_matches_dataset['attendance'].fillna(0)\n",
    "full_matches_dataset['no_audience'] = full_matches_dataset['attendance'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81bdcfb-0448-42b5-8bd8-8ca575e8423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset = full_matches_dataset.drop('notes', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ffd11-8554-468d-8828-6cc034591d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again the sum of null values for each column\n",
    "full_matches_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c018f8e-798d-48e6-ac23-ccfbc6fd95f9",
   "metadata": {},
   "source": [
    "### 5.2 Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52cef0-95f0-484c-af62-3130d7155959",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293716f-5814-484f-b990-779a5628b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f1f0e-22eb-49a9-83d8-d3a104565e53",
   "metadata": {},
   "source": [
    "### 5.3 Reformatting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125829d-2c99-42db-baf1-08d7aca3b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to a datetime\n",
    "full_matches_dataset['date'] = pd.to_datetime(full_matches_dataset['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b4904-e1e3-4c51-b550-ee4f8723565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns which are objects to integers\n",
    "full_matches_dataset['goals_for'] = full_matches_dataset['goals_for'].astype('int64')\n",
    "full_matches_dataset['goals_against'] = full_matches_dataset['goals_against'].astype('int64')\n",
    "full_matches_dataset['weather_code'] = full_matches_dataset['weather_code'].astype('int64')\n",
    "full_matches_dataset['shots'] = full_matches_dataset['shots'].astype('int64')\n",
    "full_matches_dataset['shots_on_target'] = full_matches_dataset['shots_on_target'].astype('int64')\n",
    "full_matches_dataset['free_kicks'] = full_matches_dataset['free_kicks'].astype('int64')\n",
    "full_matches_dataset['penalties'] = full_matches_dataset['penalties'].astype('int64')\n",
    "full_matches_dataset['attendance'] = full_matches_dataset['attendance'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d6d3b-d6ae-4963-ac45-5f989313ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd50c16-a082-45d2-b36c-45cde45742b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4965d-52ee-4ec0-b6d9-223fd48c53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca48107-c985-4319-a83f-6ddc84079dbb",
   "metadata": {},
   "source": [
    "### 5.4 Strip Whitespaces from Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a35070-1cc0-4b6a-849a-03361bedb345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each column in the DataFrame\n",
    "for col in full_matches_dataset.columns:\n",
    "    # Check if the column is of object type\n",
    "    if full_matches_dataset[col].dtype == 'object':\n",
    "        # Apply the strip function to the entire column\n",
    "        full_matches_dataset[col] = full_matches_dataset[col].str.strip()\n",
    "\n",
    "# Now all string columns have been stripped of leading and trailing whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e868da-38b8-4053-a163-2af376761aad",
   "metadata": {},
   "source": [
    "### 5.5 Remove special symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077ca4f-104e-4316-9fbd-3d950f2f1a77",
   "metadata": {},
   "source": [
    "In the column \"formation\" there are some values like this: '3-4-3◆' and we want to remove that symbol '◆'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0efc9c-3c35-413a-8428-e05f8437d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '◆' with an empty string\n",
    "full_matches_dataset['formation'] = full_matches_dataset['formation'].str.replace('◆', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2fc906-f81e-42dc-a8c8-35ff1cc1cadc",
   "metadata": {},
   "source": [
    "## 6. Explorative Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73354cbc-a51f-44b7-aa54-78543f018f06",
   "metadata": {},
   "source": [
    "In this chapter, we want to conduct some Explorative Data Analysis (EDA) to get an idea of what kind of data we have. We are not going to analyze every attribute but rather pick some and analyze and interpret them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc9309-3830-4567-a4d1-161aa771ac2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.1 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980dee5-6bdd-4936-a4fe-5a8880520440",
   "metadata": {},
   "source": [
    "We'll compute summary statistics for all numerical columns to assess central tendency (mean, median) and variability (standard deviation, min, max). Additionally, we'll get frequency counts for categorical variables to understand the distribution of data across different categories such as team names, results, and formations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f854f8-3dc7-46c7-b92f-1e9b968cbe68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6.1.1 General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5366bb-dfbf-4a37-906e-e5d1c26cf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical data\n",
    "numerical_stats = full_matches_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145feb37-a996-49fc-854a-f6c565f8b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency counts for categorical data\n",
    "categorical_columns = ['time_of_day', 'season', 'round', 'match_day', 'team', 'opponent', 'venue', 'captain', 'formation', 'result', 'weather_category', 'stadium', 'city', 'referee']\n",
    "categorical_stats = {column: full_matches_dataset[column].value_counts() for column in categorical_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4962184-6073-4080-9e8e-9051c4bdf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numerical Statistics:\\n\", numerical_stats)\n",
    "print(\"\\nCategorical Statistics:\")\n",
    "for column, stats in categorical_stats.items():\n",
    "    print(f\"\\n{column} Distribution:\\n\", stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b54d84-9d2c-41f0-b691-f8900b4f225d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6.1.2 General Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c387583-07ce-4a8d-9110-7c155cb975ee",
   "metadata": {},
   "source": [
    "**Numerical Data Insights**\n",
    "- **Match Timing:** The majority of matches are scheduled in the afternoon (16:00 average time), which is typical for European football leagues to accommodate audiences.\n",
    "- **Goals Scored and Conceded:** On average, teams score and concede about 1.56 goals per match. This symmetry in goals_for and goals_against implies a balanced dataset from the perspective of each team.\n",
    "- **Expected Goals:** The average expected goals (expected_goals) and expected goals against (expected_goals_against) both stand at around 1.46, which closely aligns with the actual goals scored and conceded. This suggests that the expected goals model used for the dataset is fairly accurate in predicting outcomes based on match actions.\n",
    "- **Shots and Shots on Target:** Teams take an average of nearly 13 shots per match, of which approximately 4.4 are on target. This indicates a shot accuracy rate of about 33.8%, a crucial metric for assessing offensive effectiveness.\n",
    "- **Possession:** The average possession is exactly 50%, reflecting the dataset's structured balance between the two perspectives of each match.\n",
    "- **Weather and Attendance:** The mean temperature during matches is around 8.6°C, with a precipitation average of 2.05 mm, suggesting many games are played under cold and possibly wet conditions. Despite this, the average attendance is about 25,406, although 24.7% of the games feature no audience, likely influenced by external factors such as regulations or stadium policies.\n",
    "\n",
    "**Categorical Data Insights**\n",
    "- **Season and Round Distribution:** The data spans evenly across four seasons (2021 to 2024), with most rounds featuring an equal number of matches. This uniform distribution helps in comparative season-over-season analysis.\n",
    "- **Day of the Match:** The majority of matches (about 61%) occur on Saturdays, which is a traditional match day across European leagues.\n",
    "- **Team Representation:** All teams have an equal representation of matches in the dataset except for teams that have been promoted or relegated within the timeframe, as indicated by fewer entries for some.\n",
    "- **Formations Used:** The 4-2-3-1 formation is the most popular, used in 643 matches. This formation is favored for its balance between defense and attack, which might suggest a tactical preference in the Bundesliga.\n",
    "- **Venue:** The equal split between Home and Away games for each team ensures no bias in match location, which is ideal for unbiased analytical modeling.\n",
    "- **Weather Conditions:** 'Rainy' is the most common weather condition, being reported in almost half of the matches. This could influence playing conditions and potentially the outcome of matches, something that could be explored further in predictive modeling.\n",
    "\n",
    "**Potential Areas for Further Exploration**\n",
    "- **Performance by Weather Conditions:** Analyzing how different teams perform under various weather conditions could uncover unique insights into tactical adjustments or player performances.\n",
    "- **Impact of Referees:** With detailed data on referees, investigating whether certain referees have a significant impact on the number of penalties awarded or overall match outcomes might be intriguing.\n",
    "- **Home vs. Away Analysis:** Further analysis into the performance differences between playing at home versus away could validate common beliefs about \"home advantage\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f709634-ad29-4be1-bdc2-e0636a31a7f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6.1.3 Analysis for Bayern Munich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689c19e-f330-4b69-9cce-cd24505b9a45",
   "metadata": {},
   "source": [
    "We aim to understand Bayern Munich's performance trends and patterns over the specified seasons in the dataset. This includes analyzing their scoring efficiency, defensive stability, match outcomes, and any notable variations in their gameplay based on different conditions such as home vs. away games, weather conditions, and match timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead7b49-c48f-41b7-81e2-9b4284c3eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset for Bayern Munich\n",
    "bayern_data = full_matches_dataset[full_matches_dataset['team'] == 'Bayern Munich']\n",
    "\n",
    "# Summary statistics for numerical columns specific to Bayern Munich\n",
    "bayern_numerical_stats = bayern_data.describe()\n",
    "\n",
    "# Visualizations\n",
    "# Goals For and Against Distribution\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(bayern_data['goals_for'], bins=8, kde=True, color='blue')\n",
    "plt.title('Distribution of Goals Scored by Bayern Munich')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(bayern_data['goals_against'], bins=8, kde=True, color='red')\n",
    "plt.title('Distribution of Goals Conceded by Bayern Munich')\n",
    "\n",
    "# Result Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='result', data=bayern_data, order=['W', 'D', 'L'], palette='viridis')\n",
    "plt.title('Match Outcomes for Bayern Munich')\n",
    "\n",
    "# Boxplot for shots and shots on target\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=bayern_data['shots'], color='green')\n",
    "plt.title('Boxplot of Shots Taken by Bayern Munich')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=bayern_data['shots_on_target'], color='orange')\n",
    "plt.title('Boxplot of Shots on Target by Bayern Munich')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Output numerical stats\n",
    "print(\"Bayern Munich Numerical Statistics:\\n\", bayern_numerical_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae1d98-18dc-4967-b6a1-6675c145b5a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6.1.4 Insights of Bayern Munich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72b573-9d29-45dd-85fa-e480d025734f",
   "metadata": {},
   "source": [
    "**Distribution of Goals Scored**\n",
    "- The histogram shows that the most common number of goals scored by Bayern Munich in a match is 1 or 2, with a significant frequency of matches with 3 goals as well.\n",
    "- There is a tail that extends to 8 goals, indicating that there have been a few matches where Bayern Munich has scored a very high number of goals. This is characteristic of a dominant offensive team.\n",
    "\n",
    "**Distribution of Goals Conceded**\n",
    "- The histogram indicates that Bayern Munich most commonly concedes 1 goal in a match, with matches where they concede 0 goals also being quite common.\n",
    "- The distribution drops significantly for games where they concede more than 2 goals, suggesting that their defense is quite solid, and it is rare for them to concede many goals.\n",
    "\n",
    "**Match Outcomes**\n",
    "- The count plot shows a high number of wins (denoted by 'W') compared to draws ('D') and losses ('L'), indicating a very successful period for Bayern Munich.\n",
    "- This visual evidence supports Bayern Munich's reputation as a top-performing team, likely contending for the title in most seasons.\n",
    "\n",
    "**Boxplot of Shots Taken**\n",
    "- The boxplot demonstrates that Bayern Munich consistently takes a high number of shots per match, with the median around 18.\n",
    "- The range is broad, with some matches featuring an exceptionally high shot count, highlighting Bayern's aggressive playstyle.\n",
    "\n",
    "**Boxplot of Shots on Target**\n",
    "- The number of shots on target has a tighter distribution with a lower median than the total shots taken.\n",
    "- There are a few outliers indicating matches where Bayern Munich had an unusually high number of shots on target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717b25a-aa70-4233-8697-efc8f530bfe6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6.1.5 Numerical Statistics Insights for Bayern Munich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb01e655-1a9c-4760-a446-d39428183b96",
   "metadata": {},
   "source": [
    "**Time and Season**\n",
    "- **Game Timing:** Bayern Munich's matches skew slightly later in the day compared to the league average, with a mean time around 17:00. This could be due to prime-time broadcasting slots.\n",
    "- **Seasonal Data:** The data spans the same four seasons as the overall dataset, ensuring that we have a consistent time frame for analysis.\n",
    "\n",
    "**Offensive Metrics** \n",
    "- **Goals Scored:** On average, Bayern Munich scores about 2.82 goals per match, which is significantly higher than the overall league average of 1.56 goals. This high mean is a testament to their offensive prowess.\n",
    "- **Expected Goals:** The expected goals metric at 2.42 is also higher than the league average, which indicates that Bayern Munich creates high-quality scoring chances.\n",
    "- **Shots and Shots on Target:** They take an average of 18.58 shots per match, with about 7.09 on target. These values are considerably higher than the league averages, suggesting Bayern Munich's attacking play is very active and they manage to direct a good proportion of their shots on goal.\n",
    "\n",
    "**Defensive Metrics**\n",
    "- **Goals Against:** Bayern Munich concedes 1.18 goals per match on average, which is lower than the league's average of 1.56, reflecting a strong defensive record.\n",
    "- **Expected Goals Against:** At 1.07, the expected goals against is also lower than the league average, showing that they generally do not give up many high-quality chances.\n",
    "\n",
    "**Ball Possession and Movement**\n",
    "- **Possession:** They average nearly 63% possession per match, significantly higher than the league's 50%, suggesting a dominant ball-control style.\n",
    "- **Distance Covered:** The team covers an average distance of 16.57 km per match, which is slightly lower than the overall league average. This could be indicative of Bayern Munich's style, potentially not needing to cover as much ground due to better control of the play and positioning.\n",
    "\n",
    "**Environmental and Contextual Factors**\n",
    "- **Weather:** They play in a variety of weather conditions, with precipitation and snowfall reflecting the league's diverse seasonal conditions. The attendance data shows an average of 35,166, higher than the league average, which is expected for a high-profile team like Bayern Munich.\n",
    "\n",
    "**Attendance and Audience**\n",
    "- **No Audience Matches:** About 27% of Bayern Munich's matches are played without an audience, which is slightly higher than the league average of 24.7%. This could be due to strict regulations at their home stadium or particular away games.\n",
    "\n",
    "From this data, we can conclude that Bayern Munich is an offensively dominant team with a solid defensive foundation. They are likely to be at the top end of the league, both in terms of performance and popularity. The data also suggests they are a marquee team, often playing in prime-time slots with a large fan following. The slightly higher percentage of games without an audience for Bayern Munich might indicate that their games are impacted more by external factors, possibly due to the larger crowd they draw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216f6eb-afa9-4360-8bc7-8b3b821738c1",
   "metadata": {},
   "source": [
    "### 6.2 Simple Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975d00d-93be-4354-af17-178785956a1b",
   "metadata": {},
   "source": [
    "#### 6.2.1 Histogram for goals scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062123b-6c91-4111-8c79-9147c41b4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for goals scored\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=full_matches_dataset, x='goals_for', bins=10, kde=True)\n",
    "plt.title('Distribution of Goals Scored')\n",
    "plt.xlabel('Goals Scored')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc2e221-b8f2-4225-b752-7348deed7676",
   "metadata": {},
   "source": [
    "- This histogram shows the frequency of goals scored per match. The most common number of goals scored by a team in a match is 1, as shown by the highest bar. The frequency decreases as the number of goals increases, which is typical in football matches since high-scoring games are less common.\n",
    "- There's a long tail to the right, indicating that there are a few matches where a team scores a very high number of goals, but these are outliers.\n",
    "- The distribution appears to be right-skewed, meaning that scoring more than 2 or 3 goals in a match is less frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f45a2-a3bd-4c39-9268-4a51a43c7f05",
   "metadata": {},
   "source": [
    "#### 6.2.2 Box plot for ball possession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023428a9-e725-401e-9bca-70bb98e28599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for ball possession\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=full_matches_dataset, x='possession')\n",
    "plt.title('Box Plot of Ball Possession')\n",
    "plt.xlabel('Possession (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6721eed-24c4-4e31-9829-802507516e09",
   "metadata": {},
   "source": [
    "- The box plot for ball possession shows the median possession percentage is around the 50% mark, which is expected since, on average, teams will share possession equally.\n",
    "- The interquartile range (the box) is quite narrow, suggesting that most of the data points (i.e., ball possession percentages) are close to the median. This indicates a consistency in possession statistics across matches.\n",
    "- There are no significant outliers, and the spread is relatively even, suggesting that extreme possession percentages (very low or very high) are rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8c9ea-b4ba-4c2c-89f9-7172ab173751",
   "metadata": {},
   "source": [
    "#### 6.2.3 Locations where matches are played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425d01a-876f-4dee-958a-7d11bd11ff99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "map = folium.Map(location=[51.1657, 10.4515], zoom_start=6)  # Coordinates roughly centered on Germany\n",
    "\n",
    "# Add markers for stadiums\n",
    "for idx, row in full_matches_dataset.drop_duplicates(subset=['stadium']).iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=f\"{row['stadium']} - {row['city']}\",\n",
    "        icon=folium.Icon(icon='soccer-ball-o', prefix='fa')\n",
    "    ).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83539525-5a60-40a4-9c26-c67dd9f6cc38",
   "metadata": {},
   "source": [
    "- The map has markers placed on the locations of Bundesliga stadiums. This geographic distribution can be helpful to understand regional patterns in attendance, team performance, or even how weather might affect matches.\n",
    "- The map shows that the Bundesliga teams are relatively well distributed across Germany, with a higher concentration of teams in the western part of the country.\n",
    "- This spatial information could be used to analyze if there are 'strongholds' where certain teams dominate or if performance is influenced by geographic factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9956a3ff-23c0-4ea3-88e7-8b3201102b60",
   "metadata": {},
   "source": [
    "### 6.3 Comparative Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2caa3f-32a9-43f9-a0a1-5b18db58eea4",
   "metadata": {},
   "source": [
    "#### 6.3.1 Home vs. Away Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db754772-73d7-405d-a8fc-376c720d02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate home vs away metrics\n",
    "home_away_metrics = full_matches_dataset.groupby(['team', 'venue']).agg({\n",
    "    'goals_for': 'mean',\n",
    "    'possession': 'mean',\n",
    "    'result': lambda x: (x == 'W').mean()  # Calculate win rate directly\n",
    "}).unstack()\n",
    "\n",
    "\n",
    "home_away_metrics.head()\n",
    "# Rename columns explicitly\n",
    "home_away_metrics.columns = ['goals_for_away', 'goals_for_home', 'possession_away', 'possession_home', 'win_rate_away', 'win_rate_home']\n",
    "\n",
    "# Plotting the results\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "sns.barplot(data=home_away_metrics.reset_index(), x='team', y='goals_for_home', ax=axes[0])\n",
    "axes[0].set_title('Average Goals For - Home')\n",
    "axes[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.barplot(data=home_away_metrics.reset_index(), x='team', y='goals_for_away', ax=axes[1])\n",
    "axes[1].set_title('Average Goals For - Away')\n",
    "axes[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.barplot(data=home_away_metrics.reset_index(), x='team', y='win_rate_home', ax=axes[2])\n",
    "axes[2].set_title('Win Rate - Home')\n",
    "axes[2].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce3d519-cb4d-4c2d-ad58-9323fc7850c0",
   "metadata": {},
   "source": [
    "**Average Goals For - Home vs. Away**\n",
    "- Teams score a range of average goals at home, with some teams scoring substantially more than others. This suggests a strong home-field advantage for those teams, likely due to better team morale, support from local fans, or familiarity with their own stadium.\n",
    "- The distribution of average goals at home appears to be fairly even across the board, but there are a few standout teams that score particularly high at home, which could be a key factor in their home match strategy.\n",
    "- The y-axis scale for the \"Average Goals For - Home\" chart ranges up to 3.0, while for \"Average Goals For - Away\" it goes up to 2.5. This difference in scale could visually minimize the contrast between home and away performances.\n",
    "- \n",
    "All teams, in fact, seem to have a higher average number of goals scored at home compared to away, which aligns with typical home advantage dynamics\n",
    "\n",
    "**Win Rate - Home**\n",
    "- The chart shows that while most teams do have a higher chance of winning at home, the win rate does not seem to correlate perfectly with the average number of goals scored at home, reinforcing that factors other than just scoring contribute to a team's likelihood of winning a match.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b605488-d15f-44fb-a85d-61567b28317c",
   "metadata": {},
   "source": [
    "#### 6.3.2 Head-to-Head Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8969988-c6af-4cbc-a83f-d5b20985431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating head-to-head results\n",
    "h2h_results = full_matches_dataset.groupby(['team', 'opponent']).agg({\n",
    "    'result': lambda x: (x == 'W').mean(),\n",
    "    'goals_for': 'mean',\n",
    "    'goals_against': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Example plot for Bayern Munich's head-to-head results\n",
    "bayern_h2h = h2h_results[h2h_results['team'] == 'Bayern Munich']\n",
    "\n",
    "plt.figure(figsize=(12, 8))  # Adjusted figure size for better fit\n",
    "barplot = sns.barplot(data=bayern_h2h, x='opponent', y='result', hue='opponent', dodge=False, palette='viridis')\n",
    "plt.title('Bayern Munich Head-to-Head Win Rate')\n",
    "plt.xticks(rotation=45, ha='right')  # Adjusted rotation and horizontal alignment\n",
    "plt.ylabel('Win Rate')\n",
    "plt.xlabel('Opponent')\n",
    "plt.tight_layout()  # Adjust layout to fit everything\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e760a9-3550-46c5-849e-6f90e94cae9f",
   "metadata": {},
   "source": [
    "- **Win Rate Variation:** The win rate against different teams varies significantly, which is evident from the height of the bars. Some opponents seem easier for Bayern Munich to beat than others based on historical data.\n",
    "- **Toughest Opponents:** The tallest bars represent the teams against which Bayern Munich has the highest win rate. These teams might be considered favorable matchups for Bayern Munich historically.\n",
    "- **Strongest Performance:** The shorter bars indicate opponents against which Bayern Munich has a lower win rate. These might be teams that historically pose a challenge to Bayern Munich, leading to a lower percentage of wins.\n",
    "- **Color Gradient:** The gradient color change from dark purple to yellow across the bars does not appear to follow a particular pattern; rather, it's a visual design choice. It does not seem to correlate with the win rate or any other variable.\n",
    "- **Potential for Further Analysis:** While the chart shows win rates, it does not account for draws or losses. Including additional metrics such as draw rate or loss rate could provide a more comprehensive understanding of the performance.\n",
    "- **Contextual Factors:** The win rate alone does not provide the full context. Factors such as home vs. away games, seasons, or player availability can significantly impact these results. Further analysis considering these factors could give a better understanding of the performance dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8e76fa-141c-477e-ad92-4d1518aeb054",
   "metadata": {},
   "source": [
    "### 6.4 Advanced Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fcf127-865e-40d3-8595-1fc28d439d98",
   "metadata": {},
   "source": [
    "#### 6.4.1 Impact of Weather on Match Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affac32-4dd9-4df3-a4f5-80fdbb91a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by weather category and result, and count occurrences\n",
    "weather_impact = full_matches_dataset.groupby(['weather_category', 'result']).size().unstack()\n",
    "\n",
    "# Normalize the counts to get proportions\n",
    "weather_impact = weather_impact.div(weather_impact.sum(axis=1), axis=0)\n",
    "\n",
    "# Plotting\n",
    "weather_impact.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.title('Match Outcomes by Weather Conditions')\n",
    "plt.ylabel('Proportion of Matches')\n",
    "plt.xlabel('Weather Category')\n",
    "plt.legend(title='Match Result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa62f09-d4ca-49c6-92b1-d5e1c2994e6d",
   "metadata": {},
   "source": [
    "The stacked bar chart shows the proportion of match outcomes (Win, Draw, Loss) under different weather conditions (Clear, Rainy, Snowy). It appears that weather conditions do not significantly alter the proportion of match outcomes. Wins, draws, and losses are distributed relatively evenly across different weather types, suggesting that weather may not have a strong impact on the outcome of a match. However, it's interesting to note that there are slightly more wins in clear conditions compared to rainy and snowy weather."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83782c1b-276d-47d5-881d-6cad01cec082",
   "metadata": {},
   "source": [
    "#### 6.4.2 Referee Influence on Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1463d684-7468-4114-998f-1eb22066eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by referee and count penalties\n",
    "referee_penalties = full_matches_dataset.groupby('referee')['penalties'].sum()\n",
    "\n",
    "# Sort the data to see top referees associated with penalties\n",
    "referee_penalties = referee_penalties.sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=referee_penalties.values, y=referee_penalties.index)\n",
    "plt.title('Total Penalties Awarded by Referee')\n",
    "plt.xlabel('Number of Penalties')\n",
    "plt.ylabel('Referee')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b5ac2-0ca7-47fc-8d7e-e51d2e7dffbf",
   "metadata": {},
   "source": [
    "This bar chart displays the number of penalties awarded by different referees. There is a clear variation among referees, with some giving significantly more penalties than others. This could be due to various factors, including the referee's interpretation of the game, the nature of the matches they officiate, or mere chance. Referees at the top of the chart are associated with a higher frequency of penalties, which could warrant further investigation to understand the underlying reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d3997-5812-4321-9803-774a1a4e8bda",
   "metadata": {},
   "source": [
    "#### 6.4.3 Heatmap of Goals Scored at Different Stadiums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22210cb-20e0-49fc-ba96-c55e33f77378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map centered around Germany\n",
    "map = folium.Map(location=[51.1657, 10.4515], zoom_start=6)\n",
    "\n",
    "# Prepare data for the heatmap\n",
    "# We need to aggregate goals by latitude and longitude\n",
    "goal_data = full_matches_dataset.groupby(['latitude', 'longitude']).agg({'goals_for': 'sum'}).reset_index()\n",
    "\n",
    "# Ensure the columns are floats\n",
    "goal_data['latitude'] = goal_data['latitude'].astype(float)\n",
    "goal_data['longitude'] = goal_data['longitude'].astype(float)\n",
    "goal_data['goals_for'] = goal_data['goals_for'].astype(float)\n",
    "\n",
    "# Generate a list of coordinates and number of goals scored at those coordinates\n",
    "heat_data = [[row['latitude'], row['longitude'], row['goals_for']] for index, row in goal_data.iterrows()]\n",
    "\n",
    "# Create a heat map\n",
    "HeatMap(heat_data, radius=25, blur=15, max_zoom=1).add_to(map)\n",
    "\n",
    "# Display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa357a08-23c7-4b15-9789-7176f5921a75",
   "metadata": {},
   "source": [
    "The heatmap visualizes the concentration of goals scored in the geographical locations of stadiums. Areas with a higher frequency of goals are indicated by warmer colors (red, orange). It shows that certain regions or stadiums are hotspots for goal-scoring. This could be due to factors such as the offensive play style of the home teams, the stadium's atmosphere, or even pitch conditions favoring attacking football. Teams in the areas with the highest intensity might have potent attacks or it could also indicate a trend of high-scoring games in those regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe70a5-03d3-4077-bf75-c34c69b63e6f",
   "metadata": {},
   "source": [
    "#### 6.4.4 Most Common Weather Conditions for each Stadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2512b7e-be9e-4e3f-bf7b-413856e5e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map centered around Germany\n",
    "map_germany_weather = folium.Map(location=[51.1657, 10.4515], zoom_start=6)\n",
    "\n",
    "# Group by stadium and count the most frequent weather_category\n",
    "stadium_weather = full_matches_dataset.groupby(['stadium', 'latitude', 'longitude'])['weather_category'].agg(lambda x: pd.Series.mode(x).iloc[0]).reset_index()\n",
    "\n",
    "# Define a color scheme for the weather categories\n",
    "weather_colors = {\n",
    "    'Clear': 'green',\n",
    "    'Rainy': 'blue',\n",
    "    'Cloudy': 'gray',\n",
    "    'Snowy': 'white'\n",
    "}\n",
    "\n",
    "# Iterate through the grouped DataFrame and add a marker for each stadium\n",
    "for idx, row in stadium_weather.iterrows():\n",
    "    # The mode is now assured to be a single value due to lambda function modification\n",
    "    most_common_weather = row['weather_category']\n",
    "\n",
    "    # Assign a color based on the most common weather category\n",
    "    icon_color = weather_colors.get(most_common_weather, 'red')  # Default to red if not found\n",
    "\n",
    "    # Create a marker with the color and weather information in the popup\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=f\"{row['stadium']}<br>Most Common Weather: {most_common_weather}\",\n",
    "        icon=folium.Icon(color=icon_color, icon='cloud')\n",
    "    ).add_to(map_germany_weather)\n",
    "    \n",
    "map_germany_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ef24b-5127-4901-b34c-d66c323ddd53",
   "metadata": {},
   "source": [
    "This map shows markers representing the most common weather condition at each stadium, using a color-coded scheme for different weather types. It appears that most stadiums commonly experience rainy weather, as indicated by the blue markers. A few stadiums, shown with green markers, have clear weather as the most common condition. This distribution could provide insights into regional climatic patterns and how they might affect match planning or team preparations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1b805-b16c-4075-860d-c31236edb164",
   "metadata": {},
   "source": [
    "#### 6.4.5 Impact of Audience on Team Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd9518-683c-49da-ad7e-1c586c4c5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate win rates and average goals in matches with and without an audience\n",
    "# Filter out home and away games separately\n",
    "home_games = full_matches_dataset[full_matches_dataset['venue'] == 'Home']\n",
    "away_games = full_matches_dataset[full_matches_dataset['venue'] == 'Away']\n",
    "\n",
    "# Define a function to calculate win rates and average goals\n",
    "def analyze_performance(data):\n",
    "    win_rate = data[data['result'] == 'W'].shape[0] / data.shape[0]\n",
    "    avg_goals_scored = data['goals_for'].mean()\n",
    "    return win_rate, avg_goals_scored\n",
    "\n",
    "# Home games with and without audience\n",
    "home_with_audience = home_games[home_games['no_audience'] == 0]\n",
    "home_without_audience = home_games[home_games['no_audience'] == 1]\n",
    "\n",
    "# Away games with and without audience\n",
    "away_with_audience = away_games[away_games['no_audience'] == 0]\n",
    "away_without_audience = away_games[away_games['no_audience'] == 1]\n",
    "\n",
    "# Calculate metrics\n",
    "home_audience_performance = analyze_performance(home_with_audience)\n",
    "home_no_audience_performance = analyze_performance(home_without_audience)\n",
    "away_audience_performance = analyze_performance(away_with_audience)\n",
    "away_no_audience_performance = analyze_performance(away_without_audience)\n",
    "\n",
    "# Setting up the data for plotting\n",
    "categories = ['Home with Audience', 'Home without Audience', 'Away with Audience', 'Away without Audience']\n",
    "win_rates = [home_audience_performance[0], home_no_audience_performance[0], away_audience_performance[0], away_no_audience_performance[0]]\n",
    "avg_goals = [home_audience_performance[1], home_no_audience_performance[1], away_audience_performance[1], away_no_audience_performance[1]]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Creating bars for win rates\n",
    "ax1.set_xlabel('Match Condition')\n",
    "ax1.set_ylabel('Win Rate', color='tab:red')\n",
    "ax1.bar(categories, win_rates, color='tab:red')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Instantiate a second axes that shares the same x-axis\n",
    "ax2 = ax1.twinx()  \n",
    "ax2.set_ylabel('Average Goals Scored', color='tab:blue')  # we already handled the x-label with ax1\n",
    "ax2.plot(categories, avg_goals, color='tab:blue', marker='o')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Final touches\n",
    "plt.title('Impact of Audience on Team Performance')\n",
    "fig.tight_layout()  # to ensure no overlap of labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac6b71-916a-4e03-9b31-cb0e0a069480",
   "metadata": {},
   "source": [
    "The combined bar and line graph compares the win rate and average goals scored for home and away matches, with and without an audience. The win rate is higher for home games with an audience, which is a common expectation due to the 'home advantage'. Interestingly, the win rate drops for home games without an audience, indicating that crowd support might play a significant role in boosting team performance. For away games, the win rate is lower compared to home games, and there is a slight increase when there is no audience. Average goals scored don't seem to vary significantly between these conditions. This suggests that while the presence of an audience may influence the likelihood of a win, it does not drastically change the scoring ability of a team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4397054-b5ce-40d6-ac6a-32ad382824a7",
   "metadata": {},
   "source": [
    "### 6.5 Trend Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799e0616-cb7b-4652-ba02-fe97343c472c",
   "metadata": {},
   "source": [
    "#### 6.5.1 Performance Trends Over Seasons for Home Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed903f-c724-48bb-a183-3e5a77b13837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataset\n",
    "df = full_matches_dataset.copy()\n",
    "\n",
    "# Convert date to datetime for easier handling\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter only home games to avoid double counting\n",
    "home_games = df[df['venue'] == 'Home']\n",
    "\n",
    "# Aggregate data for total wins, draws, and losses per team per season for home games only\n",
    "seasonal_home_performance = home_games.groupby(['season', 'team', 'result']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# Plotting the trends\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "for outcome in ['W', 'D', 'L']:\n",
    "    sns.lineplot(data=seasonal_home_performance, x='season', y=outcome, ax=ax, label=f'Total {outcome}s at Home')\n",
    "ax.set_title('Team Performance at Home Over Seasons')\n",
    "ax.set_ylabel('Number of Matches')\n",
    "ax.set_xlabel('Season')\n",
    "plt.xticks(seasonal_home_performance['season'].unique())  # Ensure all seasons are displayed\n",
    "plt.legend(title='Match Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc92d6f-2028-4442-a94f-da5ef9f64304",
   "metadata": {},
   "source": [
    "- **Wins:** There is a noticeable trend where the number of wins at home has generally decreased over the seasons. This might indicate that teams are finding it more challenging to secure victories at home, or the league is becoming more competitive.\n",
    "- **Draws**: The number of draws at home shows slight fluctuation but no clear trend over time. This suggests that the likelihood of a draw has remained relatively stable.\n",
    "- **Losses:** There is an increase in the number of losses at home, especially noticeable from the third season to the fourth. This could reflect the same factors contributing to the decrease in wins, such as increased competition or changes in team performance or strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a6a52-c6b2-4cfa-9cb2-d777044d7d92",
   "metadata": {},
   "source": [
    "#### 6.5.2 Trend in Goals Scored by Match Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62f1dc-8abb-4752-a998-d6461b767192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataset\n",
    "df = full_matches_dataset.copy()\n",
    "\n",
    "# Convert round to numerical format for easier plotting\n",
    "df['matchweek'] = df['round'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Calculate average goals scored by matchweek\n",
    "goals_by_week = df.groupby('matchweek')['goals_for'].mean().reset_index()\n",
    "\n",
    "# Plotting the trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=goals_by_week, x='matchweek', y='goals_for')\n",
    "plt.title('Average Goals Scored by Matchweek')\n",
    "plt.xlabel('Matchweek')\n",
    "plt.ylabel('Average Goals Scored')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d1c6b-6cd4-4830-9283-09fd934b5d75",
   "metadata": {},
   "source": [
    "- There is considerable variability in goals scored from week to week, which is to be expected in football matches.\n",
    "- There's a sharp increase towards the last matchweek, suggesting that the final games of the season might have a higher number of goals. This could be due to several factors, such as lower-ranked teams having less to lose and therefore playing more offensively, or top teams intensifying their efforts to secure titles or qualify for European competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53171cc3-8be3-491a-995d-4961a57ea2ca",
   "metadata": {},
   "source": [
    "#### 6.5.3 Effect of Time of Day on Match Outcomes For Home Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7627d-3b10-4e29-91dc-862c6495996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataset\n",
    "df = full_matches_dataset.copy()\n",
    "\n",
    "# Filter out the away games to avoid duplicate counting\n",
    "df_home_games = df[df['venue'] == 'Home']\n",
    "\n",
    "# Mapping results to correct point values\n",
    "result_map = {'W': 3, 'D': 1, 'L': 0}\n",
    "df_home_games['result_points'] = df_home_games['result'].map(result_map)\n",
    "\n",
    "# Group by time of day and calculate average result points\n",
    "time_of_day_performance = df_home_games.groupby('time_of_day')['result_points'].mean().reset_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=time_of_day_performance, x='time_of_day', y='result_points', palette='coolwarm')\n",
    "plt.title('Effect of Time of Day on Match Outcomes for Home Games')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Average Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e695932-ea0c-45c2-ba64-42a877946b4b",
   "metadata": {},
   "source": [
    "- **Afternoon games:** The graph indicates that teams earn fewer points from home games that are played in the afternoon. This could be due to a variety of factors, such as player routines and energy levels being better suited to later games, or possibly differences in the way teams approach early kick-offs.\n",
    "- **Evenening games:** Conversely, teams appear to earn more points from home games played in the evening. The reasons for this could be multifold: players might be more energized and focused during evening matches, the atmosphere created by fans under the lights could be more intense and supportive, or there could be strategic adaptations for evening games that result in better outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ef8b4-60ac-4f19-bb2f-80668672ee36",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a29f88-e7b0-4dec-8e3c-0b2d6e5f3f0a",
   "metadata": {},
   "source": [
    "In this chapter, we delve into feature engineering, a critical step in preparing our dataset for effective machine learning. We will create new features that enhance the model's predictive power and transform existing data into formats that are more suitable for analysis. This process includes encoding categorical variables and possibly scaling and normalizing data. Our aim is to develop a dataset that not only captures the essence of the underlying patterns but also optimizes the performance of our predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c443b3-c4ce-4270-8f57-dee823dd9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = full_matches_dataset\n",
    "dataset_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323600e2-cee1-4603-b658-cc613d2b0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b8b62-d6f3-4132-88d7-7f4f3bb94300",
   "metadata": {},
   "source": [
    "#### 7.1 Columns to Remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0b372-95fb-4414-8920-a9795023caae",
   "metadata": {},
   "source": [
    "It's important to focus on the features that are likely to influence the outcome of a match while avoiding redundancy and features that don't add predictive value or could introduce bias. Thus, we remove following columns from our dataset:\n",
    "- **competition**: Since it contains only \"Bundesliga\", it provides no variability or predictive value.\n",
    "- **captain**: While leadership can impact game outcomes, this variable is likely too specific and not quantifiable for useful predictions in this context.\n",
    "- **stadium, city, latitude, longitude**: These are highly specific and their predictive value is likely captured by the 'venue' (Home/Away) variable. Geographical impact is also minimal within a single country league unless specific stadium effects are proven significant, which typically requires more detailed historical data.\n",
    "- **weather_code**: Since we already have 'weather_category', 'mean_temperature', 'precipitation_sum', 'rain_sum', and 'snowfall_sum', the weather code might be redundant unless it provides additional, non-duplicated information.\n",
    "- **attendance**: This is directly derived from 'no_audience'. If 'attendance' is zero, 'no_audience' has the value 1. Otherwise it's 0.\n",
    "- **time**: Since we already have 'time_of_day' as categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8cd55-544c-4e8b-abae-2add2f807877",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = dataset_full.drop(columns=['competition', 'captain', 'stadium', 'city', 'latitude', 'longitude', 'weather_code', 'attendance', 'time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a439704-e395-4522-b29b-28492e8e0668",
   "metadata": {},
   "source": [
    "### 7.2 Aggregate Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff5cb9-2f36-4e98-8760-731f59892370",
   "metadata": {},
   "source": [
    "When preparing the model for predicting Bundesliga match outcomes, it's crucial to recognize that certain match-specific statistics cannot be predicted ahead of time but can instead be used to derive more general indicators of team performance over the course of the season. Aggregating these statistics as seasonal averages or rolling averages provides a historical perspective on a team's form and abilities, which can be a powerful predictor for future matches. Here are the specific statistics we consider aggregating:\n",
    "- **goals_for**: The total goals scored by the team can be averaged to gauge offensive strength.\n",
    "- **goals_against**: Average goals conceded can indicate the team's defensive weaknesses or strengths.\n",
    "- **expected_goals**: This provides an insight into the quality of chances created, useful for understanding how well teams convert chances into goals.\n",
    "- **expected_goals_against**: Reflects the quality of chances conceded, giving an idea of defensive solidity.\n",
    "- **shots**: Total shots taken can show how offensive and aggressive a team is in general.\n",
    "- **shots_on_target**: Indicates the accuracy and danger of the team's shots.\n",
    "- **possession**: Average possession percentage can tell you about the team's style of play and control over matches.\n",
    "- **free_kicks**: This statistic, while more variable, can give insights into the game's dynamics and possible scoring opportunities from set pieces.\n",
    "- **penalties**: The number of penalties taken can hint at the attacking pressure a team is able to exert in the box.\n",
    "- **distance_covered**: This reflects the team's physical effort and can be an indicator of their fitness and intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdba56-13c4-486e-bf41-71fdf13cf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the DataFrame is sorted properly by team and date for consistent rolling calculations\n",
    "dataset_full.sort_values(by=['team', 'date'], inplace=True)\n",
    "\n",
    "# Define the columns for which we want to calculate rolling averages\n",
    "stats_columns = [\n",
    "    'goals_for', 'goals_against', 'expected_goals', 'expected_goals_against',\n",
    "    'shots', 'shots_on_target', 'possession', 'free_kicks', 'penalties',\n",
    "    'distance_covered'\n",
    "]\n",
    "\n",
    "# We use window=5 and min_periods=5 to start calculating averages with min. 5 matches\n",
    "# while using .shift() to avoid including the match's own data in the rolling average\n",
    "for col in stats_columns:\n",
    "    dataset_full[f'{col}_rolling_mean'] = dataset_full.groupby('team')[col].transform(\n",
    "        lambda x: x.rolling(window=5, min_periods=5).mean().shift()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf16eb-ed6e-4077-814f-8335face91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the matches that have missing values\n",
    "dataset_full = dataset_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b652db-2f03-4c0a-9a49-a82c68e192d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the columns which we calculated the rolling means\n",
    "dataset_full = dataset_full.drop(stats_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ffe03-6ad9-4629-b72f-cb61832eec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930bea2-b18c-4214-b2b1-1fbc64651dec",
   "metadata": {},
   "source": [
    "### 7.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0bcd40-ec32-4695-998a-5734385e284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to encode\n",
    "categorical_cols = ['time_of_day', 'season', 'round', 'match_day', 'team', 'opponent', \n",
    "                    'venue', 'formation', 'weather_category', 'referee']\n",
    "\n",
    "# Perform one-hot encoding on categorical columns\n",
    "# The 'prefix' parameter is optional but can make our resulting columns easier to understand\n",
    "dataset_full_encoded = pd.get_dummies(dataset_full, columns=categorical_cols, prefix=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d175f2a-e00d-4049-86e0-517ed00ef06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90c590-d59c-4864-bf5d-3a0078895e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full_encoded[\"no_audience\"] = dataset_full_encoded[\"no_audience\"].map({1: True, 0: False})\n",
    "dataset_full_encoded[\"no_audience\"] = dataset_full_encoded[\"no_audience\"].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80128ec1-1db5-4348-824a-f61420c437e3",
   "metadata": {},
   "source": [
    "## 8. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9e106-110a-43dc-8c94-daf81dd8d9b8",
   "metadata": {},
   "source": [
    "In this chapter, we will proceed through several key steps to develop and assess a predictive model. We'll start by creating balanced and no-draw samples from our dataset, then split these into training and testing sets. After scaling numerical attributes, we'll train our model and evaluate its performance using key metrics. Finally, we'll interpret these results and make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a867e96-a16e-4f2a-8607-3fa3afd77225",
   "metadata": {},
   "source": [
    "### 8.1 Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2c6cf-17ce-4ad7-bfc0-a19ada926e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distribution of the target variable 'result'\n",
    "class_distribution = dataset_full_encoded['result'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the distribution\n",
    "print(class_distribution)\n",
    "\n",
    "# Visualize the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.title('Class Distribution of Match Results')\n",
    "plt.xlabel('Result')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc56fc9-de90-4f19-b1a7-afb1b9b21343",
   "metadata": {},
   "source": [
    "Analysis of the bar chart and distribution values reveals some imbalance in the outcomes of match results in our dataset:\n",
    "\n",
    "- Wins (W): Approximately 37.77%\n",
    "- Losses (L): Approximately 37.19%\n",
    "- Draws (D): Approximately 25.04%\n",
    "\n",
    "While the distribution isn't extremely skewed (it's typical for Wins and Losses to outnumber Draws in football matches), Draws are noticeably underrepresented. This underrepresentation could bias a predictive model, potentially reducing its accuracy when predicting Draws due to fewer examples for training. To address this and assess the impact on model performance, we will construct three distinct data samples:\n",
    "\n",
    "- **Imbalanced Dataset:** This sample retains all original data, reflecting the natural occurrence of results.\n",
    "- **Balanced Dataset:** We will adjust the dataset so that the number of 'W' and 'L' matches equals the number of 'D' matches, ensuring equal representation across all classes.\n",
    "- **No Draws Dataset:** This sample removes all 'D' results, enabling us to focus on a binary classification between 'W' and 'L'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3421b1-bda6-423a-82ac-bca2b9f134d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows for each result\n",
    "class_distribution = dataset_full_encoded['result'].value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e22b2e-e0b4-41d4-8628-05689dc9dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of rows for the least represented class ('D')\n",
    "min_class_size = class_distribution['D']\n",
    "print(\"Minimum class size for balancing:\", min_class_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ffbb0-f269-4782-870e-0afce966d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample min_class_size rows for each result type\n",
    "balanced_dataset = pd.concat([\n",
    "    dataset_full_encoded[dataset_full_encoded['result'] == 'W'].sample(n=min_class_size, random_state=42),\n",
    "    dataset_full_encoded[dataset_full_encoded['result'] == 'L'].sample(n=min_class_size, random_state=42),\n",
    "    dataset_full_encoded[dataset_full_encoded['result'] == 'D']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f7fc4-07d2-4b35-ac35-83afead68e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to mix the rows up (optional)\n",
    "balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f362a2-c491-4577-936e-0a678a68ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_draws_dataset = dataset_full_encoded[dataset_full_encoded['result'] != 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e868478-1b9d-4469-8522-486f8ac9d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the shape of the datasets\n",
    "print(\"Shape of the imbalanced dataset:\", dataset_full_encoded.shape)\n",
    "print(\"Shape of the balanced dataset:\", balanced_dataset.shape)\n",
    "print(\"Shape of the no draws dataset:\", no_draws_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610614bf-a7b4-458e-b677-ac6b41e09f5d",
   "metadata": {},
   "source": [
    "### 8.2 Data Splitting into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c38c21f-3be5-4f64-80ea-6b4b39f97159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'date' as it is non-predictive or inappropriate and 'result' for separation, it will be used as the target\n",
    "columns_to_drop = ['date', 'result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e06fd-9015-4cf8-8507-2bda6a2d514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features (X) and target (y) for the imbalanced dataset\n",
    "X_imbalanced = dataset_full_encoded.drop(columns_to_drop, axis=1)\n",
    "y_imbalanced = dataset_full_encoded['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd90147-e158-4d55-b84c-bfe21d81697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features (X) and target (y) for the balanced dataset\n",
    "X_balanced = balanced_dataset.drop(columns_to_drop, axis=1)\n",
    "y_balanced = balanced_dataset['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fd9ec-0cfd-46de-a3e6-eb7c012d4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features (X) and target (y) for the dataset without draws\n",
    "X_no_draws = no_draws_dataset.drop(columns_to_drop, axis=1)\n",
    "y_no_draws = no_draws_dataset['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6501724-3fcc-4c16-b902-e5428326a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original imbalanced dataset\n",
    "X_train_imbalanced, X_test_imbalanced, y_train_imbalanced, y_test_imbalanced = train_test_split(\n",
    "    X_imbalanced, y_imbalanced, test_size=0.2, random_state=9991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d4745-4054-4ce1-9a1c-c6b843cb5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the balanced dataset\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=9991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d289ae8-252e-434c-a940-c598bbf9488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset without draws\n",
    "X_train_no_draws, X_test_no_draws, y_train_no_draws, y_test_no_draws = train_test_split(\n",
    "    X_no_draws, y_no_draws, test_size=0.2, random_state=9991)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bcb46-14a9-4890-8514-11311e64ac14",
   "metadata": {},
   "source": [
    "### 8.3 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d12d84-a1d0-4bd7-bbe0-af16fec7a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale imbalance training dataset with StandardScaler\n",
    "scaler_imbalanced = StandardScaler()\n",
    "\n",
    "numerical_columns = [\n",
    "    'goals_for_rolling_mean',\n",
    "    'goals_against_rolling_mean',\n",
    "    'expected_goals_rolling_mean',\n",
    "    'expected_goals_against_rolling_mean',\n",
    "    'shots_rolling_mean',\n",
    "    'shots_on_target_rolling_mean',\n",
    "    'possession_rolling_mean',\n",
    "    'free_kicks_rolling_mean',\n",
    "    'penalties_rolling_mean',\n",
    "    'distance_covered_rolling_mean',\n",
    "    'mean_temperature',\n",
    "    'precipitation_sum',\n",
    "    'rain_sum',\n",
    "    'snowfall_sum'\n",
    "]\n",
    "\n",
    "X_train_imbalanced[numerical_columns] = scaler_imbalanced.fit_transform(X_train_imbalanced[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5b5ff-11fe-4fa6-92ce-1a0ef2c7ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale balanced training dataset with StandardScaler\n",
    "scaler_balanced = StandardScaler()\n",
    "\n",
    "numerical_columns = [\n",
    "    'goals_for_rolling_mean',\n",
    "    'goals_against_rolling_mean',\n",
    "    'expected_goals_rolling_mean',\n",
    "    'expected_goals_against_rolling_mean',\n",
    "    'shots_rolling_mean',\n",
    "    'shots_on_target_rolling_mean',\n",
    "    'possession_rolling_mean',\n",
    "    'free_kicks_rolling_mean',\n",
    "    'penalties_rolling_mean',\n",
    "    'distance_covered_rolling_mean',\n",
    "    'mean_temperature',\n",
    "    'precipitation_sum',\n",
    "    'rain_sum',\n",
    "    'snowfall_sum'\n",
    "]\n",
    "\n",
    "X_train_balanced[numerical_columns] = scaler_balanced.fit_transform(X_train_balanced[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f705084-81b2-4d8e-b7f2-3b6080359f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale dataset without draws with StandardScaler\n",
    "scaler_no_draws = StandardScaler()\n",
    "\n",
    "numerical_columns = [\n",
    "    'goals_for_rolling_mean',\n",
    "    'goals_against_rolling_mean',\n",
    "    'expected_goals_rolling_mean',\n",
    "    'expected_goals_against_rolling_mean',\n",
    "    'shots_rolling_mean',\n",
    "    'shots_on_target_rolling_mean',\n",
    "    'possession_rolling_mean',\n",
    "    'free_kicks_rolling_mean',\n",
    "    'penalties_rolling_mean',\n",
    "    'distance_covered_rolling_mean',\n",
    "    'mean_temperature',\n",
    "    'precipitation_sum',\n",
    "    'rain_sum',\n",
    "    'snowfall_sum'\n",
    "]\n",
    "\n",
    "X_train_no_draws[numerical_columns] = scaler_no_draws.fit_transform(X_train_no_draws[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982a651-a47e-475a-b3d4-010f2aec1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training and Testing set sizes for each dataset:\")\n",
    "print(\"Imbalanced - Train: {}, Test: {}\".format(X_train_imbalanced.shape, X_test_imbalanced.shape))\n",
    "print(\"Balanced - Train: {}, Test: {}\".format(X_train_balanced.shape, X_test_balanced.shape))\n",
    "print(\"No Draws - Train: {}, Test: {}\".format(X_train_no_draws.shape, X_test_no_draws.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371e302-abf0-4613-9d45-31a604282a2f",
   "metadata": {},
   "source": [
    "### 8.4 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884b807-0880-4f53-b1ee-cb8ec8007ced",
   "metadata": {},
   "source": [
    "Now we want to create the classification model. We decide to use a Random Forest Classifier for several reasons. Random Forest is an ensemble learning method that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes of the individual trees. This model is particularly well-suited for our dataset for the following reasons:\n",
    "- **Handling Imbalanced Data**: Random Forest can handle imbalances naturally because the ensemble model reduces variance without increasing bias. Each tree in the forest considers only a subset of features and data points, allowing it to capture diverse patterns in the data. This characteristic makes it more robust to noise and variance in class distribution.\n",
    "- **Feature Importance**: Random Forest provides a straightforward indication of feature importance. Given our dataset with a diverse range of features from one-hot encoded categories to rolling averages of match statistics, understanding which features are most influential in predicting outcomes can provide valuable insights.\n",
    "- **Non-linear Relationships**: Unlike logistic regression, Random Forest does not assume any linearity in the data. It can model complex interactions between features effectively, which is suitable for sports outcomes where interactions can be non-intuitive or complex.\n",
    "- **Overfitting Control**: While decision trees tend to overfit, the ensemble nature of Random Forest, which averages multiple trees, generally results in a model that generalizes better to unseen data.\n",
    "- **Flexibility and Ease of Use**: Random Forest requires very little tuning for decent initial performance. While more sophisticated models might offer slightly higher performance, Random Forest tends to work well with a default set of parameters which makes it a great starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589de60-186f-4600-8ff1-6790f141e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Random Forest Classifier\n",
    "rf_classifier_imbalanced = RandomForestClassifier(n_estimators=100, random_state=9991)\n",
    "rf_classifier_balanced = RandomForestClassifier(n_estimators=100, random_state=9991)\n",
    "rf_classifier_no_draws = RandomForestClassifier(n_estimators=100, random_state=9991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9dbe55-0aae-4498-9acf-819b7b8ea21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the imbalanced dataset\n",
    "rf_classifier_imbalanced.fit(X_train_imbalanced, y_train_imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92ca30-5448-4dfb-af28-0ad5d063d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the balanced dataset\n",
    "rf_classifier_balanced.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab244a-8ed7-4626-b171-4d1e449e3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the dataset without draws\n",
    "rf_classifier_no_draws.fit(X_train_no_draws, y_train_no_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60858a07-98db-4dbb-91d9-65e5830ba423",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imbalanced[numerical_columns] = scaler_imbalanced.transform(X_test_imbalanced[numerical_columns])\n",
    "\n",
    "# Predict on the test set for imbalanced data\n",
    "y_pred_imbalanced = rf_classifier_imbalanced.predict(X_test_imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a308d-45bf-4d9f-a884-2c3295ad1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_balanced[numerical_columns] = scaler_balanced.transform(X_test_balanced[numerical_columns])\n",
    "\n",
    "# Predict on the test set for balanced data\n",
    "y_pred_balanced = rf_classifier_balanced.predict(X_test_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b36f6-7530-4403-a68f-b703dc8386f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_no_draws[numerical_columns] = scaler_no_draws.transform(X_test_no_draws[numerical_columns])\n",
    "\n",
    "# Predict on the test set for no draws data\n",
    "y_pred_no_draws = rf_classifier_no_draws.predict(X_test_no_draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde2bed-8fc3-455e-b407-29f2fd16bd9a",
   "metadata": {},
   "source": [
    "### 8.5 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac03ce-d311-4aaf-8a58-a5090678fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imbalanced Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_imbalanced, y_pred_imbalanced))\n",
    "\n",
    "report = classification_report(y_test_imbalanced, y_pred_imbalanced, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fff73-9064-446e-a94b-2cf33f4684cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balanced Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_balanced, y_pred_balanced))\n",
    "\n",
    "report = classification_report(y_test_balanced, y_pred_balanced, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac5e2c-55af-4b11-9a5d-6cb1ce3f12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No Draws Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_no_draws, y_pred_no_draws))\n",
    "\n",
    "report = classification_report(y_test_no_draws, y_pred_no_draws, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68663e2-0c0a-48db-96d2-524327b6b0e8",
   "metadata": {},
   "source": [
    "### 8.6 Interpreting Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e0ca5",
   "metadata": {},
   "source": [
    "Before interpreting the outcomes from each dataset, let's first define the key metrics used in evaluating classification models:\n",
    "\n",
    "1. **Accuracy:** The ratio of correctly predicted observations to the total observations. It provides an overall measure of how often the model is correct.\n",
    "2. **Precision:** The ratio of correctly predicted positive observations to the total predicted positives. It answers the question, \"Of all the labels the model predicted to be positive, how many are actually positive?\"\n",
    "3. **Recall (Sensitivity):** The ratio of correctly predicted positive observations to all observations in the actual class. It answers, \"Of all the actual positives, how many did the model correctly predict as positive?\"\n",
    "4. **F1-Score:** The weighted average of Precision and Recall. This score takes both false positives and false negatives into account. It is a good way to show that a class has a good balance between Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a561e2-30de-4632-9335-97be8a0edafd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 8.6.1 Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5019363-b128-404a-a529-bc2e34a880c4",
   "metadata": {},
   "source": [
    "- **Accuracy (46.67%):** This is slightly above a random guess (which would be 33% for three equally likely outcomes). This indicates that the classifier is correct less than half of the time across all classes, suggesting that the model struggles with making accurate predictions.\n",
    "- **Precision:** The model has moderate precision for **'L' (46.86%)** and **'W' (47.51%)**, but very low precision for **'D' (36.36%)**. This suggests that when the model predicts a draw, it's often incorrect.\n",
    "- **Recall:** Recall is highest for **'W' (66.88%)**, indicating the model is relatively better at identifying wins. However, it's particularly poor at identifying **draws (6.61%)**, meaning most actual draws are missed by the model.\n",
    "- **F1-Score:** The F1-scores are relatively low across all classes, with the highest being **55.56% for wins**, indicating that the model does not balance precision and recall well, especially for draws."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2a895-db77-4bd5-b3f1-e7394078bb70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 8.6.2 Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a57c7c-7974-44fc-9e63-510998fa9819",
   "metadata": {},
   "source": [
    "- **Accuracy (47.63%):** This dataset shows a slightly better accuracy than the imbalanced set, but still under 50%, indicating challenges in making correct predictions across the board.\n",
    "- **Precision:** The precision is more balanced across classes, with the highest for **'L' (55.12%)**. This indicates a moderate improvement in predicting losses accurately when the classes are balanced.\n",
    "- **Recall:** The recall rates are more evenly distributed, with **'W'** achieving the highest at **51.52%**. This suggests the model has improved in recognizing each class due to balancing.\n",
    "- **F1-Score:** The F1-scores are closer together but still reflect moderate performance. The balanced training set seems to have helped in evening out the recall and precision to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19362db8-2f40-4c93-9400-0af127e4dd0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 8.6.3 No Draws Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab93ec2-b24b-4c06-a25e-959638d9b5e3",
   "metadata": {},
   "source": [
    "- **Accuracy (63.80%):** This is significantly higher than in the datasets that included draws. This suggests that removing the draw class, which might be more ambiguous or harder to predict, allows the model to perform better on the remaining classes. By removing 'Draws', the model could focus on distinguishing between 'Wins' and 'Losses', which might be more straightforward due to clearer differences in their features (e.g., goals scored, possession). However, this approach also reduces the model’s utility by narrowing its applicative scope—i.e., it can no longer predict draws.\n",
    "- **Precision:** The precision is fairly balanced between **'L'** and **'W'**, both above 62%, which is better compared to the other datasets.\n",
    "- **Recall:** The recall rates are similar to the precision rates, indicating that the model is relatively effective at identifying wins and losses when draws are not a factor.\n",
    "- **F1-Score:** The F1-scores are close to 65% for both classes, which are the highest across all datasets. This indicates a good balance between recall and precision when the model does not have to predict draws."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42975b9f-43d2-426c-8def-e4f21e4bb146",
   "metadata": {},
   "source": [
    "#### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4b224-fae0-473c-ad11-9e0ebd46c952",
   "metadata": {},
   "source": [
    "- The model performs better when the dataset does not include draws, possibly due to the reduced complexity of the classification task.\n",
    "- Balancing the dataset slightly improves the model's performance, particularly in terms of equity across metrics like precision, recall, and F1-score.\n",
    "- The imbalanced dataset presents significant challenges, particularly in predicting draws accurately, as evidenced by low recall and F1-scores for the 'D' class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38341f22-11a6-49b7-9f3a-f1d4ee5b8b1e",
   "metadata": {},
   "source": [
    "### 8.7 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa0da8-2d40-4bb4-a46e-46ccf37f11df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    cm_df = pd.DataFrame(cm, index=classes, columns=classes)  # Create a DataFrame for easy plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbc119-5c50-474d-9d91-234af97d5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"W\", \"L\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95058395-8790-4c99-8db7-fcc271ce6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for the imbalanced dataset\n",
    "plot_confusion_matrix(y_test_imbalanced, y_pred_imbalanced, class_names, title='Confusion Matrix for Imbalanced Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be26e42-38ba-499b-a406-8c4e584190e8",
   "metadata": {},
   "source": [
    "The model demonstrates a preference for predicting Wins and Losses over Draws, which is expected given the imbalance in the dataset. There is a significant number of Losses and Draws being incorrectly predicted as Wins. This suggests that features that are strong indicators of Wins may not be as exclusive as needed to differentiate between the other outcomes. The model seems to be challenged by Draws, often confusing them with Wins, which could indicate that characteristics of Draw matches are not distinctly captured by the model or are too similar to those of Win matches in the training data. **Important:** If the classes are not equally represented, the accuracy score is not sufficient to interpret!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e22cdd7-2f56-42f9-83c0-8e9387015f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for the balanced dataset\n",
    "plot_confusion_matrix(y_test_balanced, y_pred_balanced, class_names, title='Confusion Matrix for Balanced Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026b346-60e6-47f8-a25f-a5919ab9e055",
   "metadata": {},
   "source": [
    "The balanced dataset shows a more uniform distribution of correct predictions across all classes, but the model still struggles with Draws, misclassifying them as Wins or Losses almost equally. This could imply that while the model has now been exposed to more examples of Draws, distinguishing features for Draws are still not being captured effectively. The similar number of misclassifications between Wins as Losses and vice versa indicates the model does not have a strong bias towards a particular outcome, which is an improvement over the imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86968b1-245d-4ff3-897d-1070cde86318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for the dataset without draws\n",
    "plot_confusion_matrix(y_test_no_draws, y_pred_no_draws, class_names[:-1], title='Confusion Matrix for No Draws Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06eb661-4ef5-44cc-a8c9-205510ffbd86",
   "metadata": {},
   "source": [
    "Excluding Draws results in the model's highest performance, indicating a clearer distinction between the features of Wins and Losses. However, there is still a notable number of each being confused for the other. The model's higher accuracy here suggests that when the ambiguity of Draws is removed, the remaining classes are more easily separated, possibly due to more definitive features or less overlap in the feature space between Wins and Losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910218b-3e6a-4082-9ae7-576660f89ce8",
   "metadata": {},
   "source": [
    "### 8.8 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26269e-a675-4bf2-9aef-115942e3da14",
   "metadata": {},
   "source": [
    "Given that the model without draws demonstrates the highest accuracy among the ones we've considered, it is a strong candidate for further optimization. Therefore, we'll proceed with hyperparameter tuning on this model. Hyperparameter tuning involves adjusting the parameters of the Random Forest algorithm to find the combination that produces the best predictive performance. We could use methods such as grid search or random search to systematically experiment with different hyperparameter values. Through this process, we aim to enhance the model's ability to generalize to new data, further improving its predictive power on unseen matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becdc95e-542f-4dcc-be25-2435b056c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 15, 20, 25, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10, 15],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4, 5],    # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True, False]        # Method of selecting samples for training each tree\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886cead-a086-4ea7-8122-5f5114bf8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model to tune\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf_base, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_no_draws, y_train_no_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea204a-a4c5-44bf-b682-384c7956f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9e1bb-a080-4168-80ee-d3b8031b3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best parameters to create a new Random Forest model\n",
    "rf_optimized = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da2a25-94ff-454d-879f-dcbccb577e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the optimized model\n",
    "y_pred_optimized = rf_optimized.predict(X_test_no_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0b1a5-8097-4c75-819e-ec0d558aa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model\n",
    "print(\"Accuracy of the optimized model:\", accuracy_score(y_test_no_draws, y_pred_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db53271-88f8-4a9c-90d1-f4a14d2428c7",
   "metadata": {},
   "source": [
    "The improved accuracy score, now at approximately 64.09% for the optimized Random Forest model, suggests that the hyperparameter tuning process has provided some benefit. Even a slight increase in accuracy can be significant in predictive modeling, particularly in complex tasks such as sports outcome predictions where many factors can influence the result. The optimized model has likely found a better balance between bias and variance, adapting more effectively to the patterns within our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3244d-1fd8-4217-bcb0-fbcfa462b3ee",
   "metadata": {},
   "source": [
    "### 8.9 ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f3b7e-7cb4-406f-b3d8-568437a25b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probabilities for the positive class (Win or Lose)\n",
    "y_probs_optimized = rf_optimized.predict_proba(X_test_no_draws)[:, 1]  # Change [:,1] depending on how your classes are ordered\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_test_no_draws.map({'W': 1, 'L': 0}), y_probs_optimized)  # Ensure mapping is correct for binary case\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for No Draws Dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40109f3b-a5fb-4593-9b30-a5543c2aa1ad",
   "metadata": {},
   "source": [
    "- **Area Under Curve (AUC) of 0.72**: This value indicates a good predictive ability. An AUC of 0.5 would suggest no discriminative ability (equivalent to random guessing), while an AUC of 1.0 represents perfect classification.\n",
    "- **Curve Shape**: The ROC curve is above the diagonal line of no-discrimination (the dashed blue line), which indicates that the classifier is performing better than random guessing. The curve approaches the top left corner, which implies higher true positive rates for lower false positive rates, a desirable trait in a predictive model.\n",
    "- **True Positive Rate (TPR)**: Also known as recall or sensitivity, this indicates the proportion of actual positive cases that were correctly identified. The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
    "- **False Positive Rate (FPR)**: This shows the proportion of actual negative cases that were incorrectly classified as positive. The goal is to minimize this rate, which is achieved by the curve staying towards the bottom of the plot as the TPR increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761adb59-6329-4329-9d38-9905bed611d6",
   "metadata": {},
   "source": [
    "### 8.10 Get Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286c03a-c05b-4ad6-bd7f-f2352b8d9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf_optimized.feature_importances_\n",
    "\n",
    "# Initialize dictionary to hold the summed importance of the original features\n",
    "total_importances = {}\n",
    "\n",
    "# Loop over each feature importance and add it to the corresponding original feature\n",
    "for col, importance in zip(X_train_no_draws.columns, feature_importances):\n",
    "    # Determine the original feature's name based on the presence of specific substrings\n",
    "    if '_rolling_' in col:\n",
    "        original_feature = col.replace('_rolling_', '_')\n",
    "    elif '_' in col:  # Handle one-hot encoded categorical features\n",
    "        original_feature = col.rsplit('_', 1)[0]\n",
    "    else:\n",
    "        original_feature = col\n",
    "    \n",
    "    # Sum the importances\n",
    "    total_importances[original_feature] = total_importances.get(original_feature, 0) + importance\n",
    "\n",
    "# Sort the features by their total importance\n",
    "sorted_total_importances = sorted(total_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top 10 most important features\n",
    "top_n = min(10, len(sorted_total_importances))  # Adjust in case there are fewer than 10 features\n",
    "top_features = sorted_total_importances[:top_n]\n",
    "top_names = [feature[0] for feature in top_features]\n",
    "top_scores = [feature[1] for feature in top_features]\n",
    "\n",
    "# Create a horizontal bar chart for the top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_n), top_scores[::-1], align='center')  # Bars are plotted top to bottom\n",
    "plt.yticks(range(top_n), top_names[::-1])  # Labels are ordered from top to bottom\n",
    "plt.xlabel('Summed Importance')\n",
    "plt.title('Top 10 Overall Feature Importances')\n",
    "plt.tight_layout()  # Adjust the plot to ensure everything fits without overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c6b02-250e-4011-87ad-b7ae0acc61ea",
   "metadata": {},
   "source": [
    "1. **Opponent**: The most influential factor is the 'Opponent' team, suggesting that the strength or style of the opposing team is highly indicative of the match outcome. This makes sense as some teams may have historical dominance over others, or particular playing styles that clash.\n",
    "2. **Possession Mean:** Ball possession is a critical aspect of football, with higher possession often indicating control over the game. Teams that maintain possession are typically able to dictate the pace and create more scoring opportunities.\n",
    "3. **Team:** Similar to 'Opponent', the importance of 'Team' indicates that the specific characteristics and abilities of the team itself are crucial for the game's outcome. This includes factors like team form, strategy, and player quality.\n",
    "4. **Expected Goals Mean (xG):** This metric estimates the number of goals a team should have scored based on the quality of their chances. A higher xG suggests more and better scoring opportunities, which is logically linked to winning matches.\n",
    "5. **Shots Mean:**: The average number of shots taken correlates with scoring opportunities. More shots generally mean more chances to score, though this does not account for the quality of those shots.\n",
    "6. **Expected Goals Against Mean (xGA):** This is the defensive counterpart to xG, estimating the expected goals conceded. A lower xGA means a team is conceding fewer high-quality chances, indicating solid defensive performance.\n",
    "7. **Venue**: Playing at 'Home' or 'Away' can have a significant impact on a team's performance due to factors like familiarity with the pitch, crowd support, and travel fatigue.\n",
    "8. **Distance Covered Mean:** The average distance players cover during a match can reflect their work rate and effort. Teams that cover more distance might be more aggressive in pressing and creating plays.\n",
    "9. **Referee:** Different referees can have varying styles of officiating, which can affect the flow of the game. Some may call more fouls, influencing the number of set-pieces, while others allow play to continue more often.\n",
    "10. **Goals For Mean:** The average number of goals scored is a direct measure of a team's offensive effectiveness. Consistently scoring goals is a clear path to winning matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffae04-7f61-4a60-88cc-b52129626627",
   "metadata": {},
   "source": [
    "### 8.11 Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c931a25-717c-476b-a80b-0c9f1002e7ac",
   "metadata": {},
   "source": [
    "Now we want to predict a game.\n",
    "\n",
    "**Borussia Dortmund vs. Bayer Leverkusen** (Sunday, 21st April 2024)\n",
    "- **Location**: Home\n",
    "- **Time**: 15:00\n",
    "- **Matchweek**: 30\n",
    "- **Audience**: Yes\n",
    "- **Referee**: Daniel Schlager\n",
    "\n",
    "**Borussia Dortmund Stats**\n",
    "- **Goals in the last 5 matches**: goals_for_rolling_mean = mean([1, 1, 0, 2, 1])\n",
    "- **Goals conceded in the last 5 matches**: goals_against_rolling_mean = mean([1, 1, 3, 2, 2])\n",
    "- **Expected goals in the last 5 matches**: expected_goals_rolling_mean = mean([2.5, 2, 1.5, 1.8, 2.2])\n",
    "- **Expected conceded goals in the last 5 matches**: expected_goals_against_rolling_mean = mean([0.4, 0.1, 0.9, 1.1, 1.2])\n",
    "- **Shots in the last 5 matches**: shots_rolling_mean = mean([10, 12, 9, 11, 12])\n",
    "- **Shots on target in the last 5 matches**: shots_on_target_rolling_mean = mean([7, 6, 3, 8, 9])\n",
    "- **Possession in the last 5 matches**: possession_rolling_mean = mean([45, 60, 42, 65, 70])\n",
    "- **Freekicks in the last 5 matches**: free_kicks_rolling_mean = mean([0, 1, 1, 0, 1])\n",
    "- **Penalties in the last 5 matches**: penalties_rolling_mean = mean([0, 0, 1, 0, 0])\n",
    "- **Average distance covered in the last 5 matches**: distance_covered_rolling_mean = mean([19.5, 18.5, 15.1, 17.6, 18.3])\n",
    "\n",
    "To get the weather data we have to call the weather API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e957144-45f3-4c98-b0ea-799363a7c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "url = \"https://api.open-meteo.com/v1/forecast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9039e2-694d-43b1-b247-29db2ee28a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(columns=['date', 'latitude', 'longitude', 'weather_code', 'min_temperature','max_temperature', 'precipitation_sum', 'rain_sum', 'snowfall_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abfea0f-bc08-4726-8530-eb729e46df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the weather API request\n",
    "params = {\n",
    "    \"latitude\": 51.4926,\n",
    "    \"longitude\": 7.45184,\n",
    "    \"start_date\": \"2024-04-21\",\n",
    "    \"end_date\": \"2024-04-21\",\n",
    "    \"daily\": [\"weather_code\", \"temperature_2m_max\", \"temperature_2m_min\", \"precipitation_sum\", \"rain_sum\", \"snowfall_sum\"],\n",
    "    \"timezone\": \"Europe/Berlin\"\n",
    "}\n",
    "\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "response = responses[0]\n",
    "\n",
    "# Process daily data. The order of variables needs to be the same as requested.\n",
    "daily = response.Daily()\n",
    "\n",
    "weather_df[\"date\"] = pd.date_range(\n",
    "    start = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = daily.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")\n",
    "weather_df[\"latitude\"] = response.Latitude()\n",
    "weather_df[\"longitude\"] = response.Longitude()\n",
    "weather_df[\"weather_code\"] = daily.Variables(0).ValuesAsNumpy()\n",
    "weather_df[\"max_temperature\"] = daily.Variables(1).ValuesAsNumpy()\n",
    "weather_df[\"min_temperature\"] = daily.Variables(2).ValuesAsNumpy()\n",
    "weather_df[\"precipitation_sum\"] = daily.Variables(3).ValuesAsNumpy()\n",
    "weather_df[\"rain_sum\"] = daily.Variables(4).ValuesAsNumpy()\n",
    "weather_df[\"snowfall_sum\"] = daily.Variables(5).ValuesAsNumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505e94e-b307-4c4e-9d9f-dd0a6913b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temperature = ((weather_df[\"min_temperature\"].astype(float).iloc[0] + weather_df[\"max_temperature\"].astype(float).iloc[0]) / 2)\n",
    "precipitation_sum = weather_df[\"precipitation_sum\"].astype(float).iloc[0]\n",
    "rain_sum = weather_df[\"rain_sum\"].astype(float).iloc[0]\n",
    "snowfall_sum = weather_df[\"snowfall_sum\"].astype(float).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402efa4-d87c-470c-9085-109ee50748cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_mean = np.mean([1, 1, 0, 2, 1])\n",
    "goals_against_mean = np.mean([1, 1, 3, 2, 2])\n",
    "expected_goals_rolling_mean = np.mean([2.5, 2, 1.5, 1.8, 2.2])\n",
    "expected_goals_against_rolling_mean = np.mean([0.4, 0.1, 0.9, 1.1, 1.2])\n",
    "shots_rolling_mean = np.mean([10, 12, 9, 11, 12])\n",
    "shots_on_target_rolling_mean = np.mean([7, 6, 3, 8, 9])\n",
    "possession_rolling_mean = np.mean([45, 60, 42, 65, 70])\n",
    "free_kicks_rolling_mean = np.mean([0, 1, 1, 0, 1])\n",
    "penalites_rolling_mean = np.mean([0, 0, 1, 0, 0])\n",
    "distance_covered_rolling_mean = np.mean([19.5, 18.5, 15.1, 17.6, 18.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87bcf7-fe80-46e8-a890-ce1e3d53512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    'team_Dortmund': True,\n",
    "    'opponent_Bayer Leverkusen': True,\n",
    "    'match_day_Sun': True,\n",
    "    'time_of_day_Afternoon': True,\n",
    "    'referee_Daniel Schlager': True,\n",
    "    'no_audience': False,\n",
    "    'round_Matchweek 30': True,\n",
    "    'venue_Home': True,\n",
    "    'formation_4-4-2': True,\n",
    "    'weather_category_Rainy': True,\n",
    "    'season_2024': True,\n",
    "    'mean_temperature': mean_temperature,\n",
    "    'precipitation_sum': precipitation_sum,\n",
    "    'rain_sum': rain_sum,\n",
    "    'snowfall_sum': snowfall_sum,\n",
    "    'goals_for_rolling_mean': goals_mean,\n",
    "    'goals_against_rolling_mean': goals_against_mean,\n",
    "    'expected_goals_rolling_mean': expected_goals_rolling_mean,\n",
    "    'expected_goals_against_rolling_mean': expected_goals_against_rolling_mean,\n",
    "    'shots_rolling_mean': shots_rolling_mean,\n",
    "    'shots_on_target_rolling_mean': shots_on_target_rolling_mean,\n",
    "    'possession_rolling_mean': possession_rolling_mean,\n",
    "    'free_kicks_rolling_mean': free_kicks_rolling_mean,\n",
    "    'penalties_rolling_mean': penalites_rolling_mean,\n",
    "    'distance_covered_rolling_mean': distance_covered_rolling_mean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e8fd3-bf72-4753-a29d-c7adaeec5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary into a DataFrame\n",
    "input_df = pd.DataFrame([input_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8e312-0db4-49e5-995c-963ff3140f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring the DataFrame matches the training structure and data types\n",
    "missing_columns = set(X_train_no_draws.columns) - set(input_df.columns)\n",
    "for col in missing_columns:\n",
    "    input_df[col] = False\n",
    "    input_df[col] = input_df[col].astype(bool)  # Ensure boolean type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496362ee-e123-44eb-9e58-bfa1b96e3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering columns to match training data\n",
    "input_df = input_df.reindex(columns=X_train_no_draws.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fd40e-17bc-45ca-adf6-f9c6ebc2e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical values\n",
    "numerical_columns = [\n",
    "    'goals_for_rolling_mean', 'goals_against_rolling_mean',\n",
    "    'expected_goals_rolling_mean', 'expected_goals_against_rolling_mean',\n",
    "    'shots_rolling_mean', 'shots_on_target_rolling_mean',\n",
    "    'possession_rolling_mean', 'free_kicks_rolling_mean',\n",
    "    'penalties_rolling_mean', 'distance_covered_rolling_mean',\n",
    "    'mean_temperature', 'precipitation_sum', 'rain_sum', 'snowfall_sum'\n",
    "]\n",
    "\n",
    "# Apply the scaler to these columns\n",
    "input_df[numerical_columns] = scaler_no_draws.transform(input_df[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ce468-bd98-4c8d-be4f-9e56f2fbb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the input dataframe to predict with our model\n",
    "predicted_result = rf_optimized.predict(input_df)\n",
    "predicted_proba = rf_optimized.predict_proba(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4e8d6-d136-410b-b357-d93ba25ba9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels\n",
    "class_labels = rf_optimized.classes_\n",
    "# Get the predicted probabilities for the first sample\n",
    "probabilities = predicted_proba[0]\n",
    "# Zip together the class labels with their corresponding probabilities\n",
    "label_probability_pairs = list(zip(class_labels, probabilities))\n",
    "# Print the probabilities and their labels\n",
    "for label, probability in label_probability_pairs:\n",
    "    print(f\"{label}: {probability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415222e5-1283-43ce-98ec-06d1bacb6f56",
   "metadata": {},
   "source": [
    "##### Our model predicts that Dortmund is going to **win** that game with a propability of **59.97%**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
